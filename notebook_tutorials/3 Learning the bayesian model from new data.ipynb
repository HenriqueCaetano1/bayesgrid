{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42817cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not available, if using conda: `conda install gxx`\n",
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions for saving are defined.\n",
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandapower as pp\n",
    "import pandapower.networks as pn\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Import our custom Bayesian model classes\n",
    "\n",
    "from bayesgrid import BayesianPowerModel, BayesianFrequencyModel, BayesianDurationModel, BayesianImpedanceModel\n",
    "\n",
    "from bayesgrid import create_osm_pandapower_network,save_bus_metric_samples,save_power_phase_samples,save_impedance_samples\n",
    "\n",
    "from bayesgrid import (\n",
    "        preprocess_power_and_phase_data, \n",
    "        preprocess_frequency_data, \n",
    "        preprocess_duration_data, \n",
    "        preprocess_impedance_data\n",
    "    )\n",
    "\n",
    "# Suppress warnings for a cleaner tutorial\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fccd5f8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ðŸ““ Tutorial: Training New Models with `bayesgrid`\n",
    "\n",
    "While `bayesgrid` comes with powerful, pre-trained models, its true strength lies in its ability to learn from *your* data. If you have a dataset from a specific utility or region, you can train `bayesgrid` to generate synthetic networks that match *your* local conditions.\n",
    "\n",
    "This tutorial will guide you through:\n",
    "\n",
    "1.  Creating a dummy (artificial) dataset that has the required columns.\n",
    "2.  Using the built-in `preprocess_` functions to prepare your data.\n",
    "3.  Calling the `.learn()` method for each of the four main model types.\n",
    "4.  Saving your new, custom-trained model traces.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf5e1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Artificial Bus Data ---\n",
      "   bus_id  hop_distance_normalized phases        P_A        P_B        P_C  \\\n",
      "0       0                 0.374540      A  19.829463   0.000000   0.000000   \n",
      "1       1                 0.950714    ABC  74.757335  79.495309   7.693147   \n",
      "2       2                 0.731994    ABC  22.020546  29.944968  14.466186   \n",
      "3       3                 0.598658      B   0.000000  40.784669   0.000000   \n",
      "4       4                 0.156019      B   0.000000  29.913007   0.000000   \n",
      "\n",
      "   FIC_total  duration  \n",
      "0          2  0.000000  \n",
      "1          3  0.000000  \n",
      "2          3  2.955830  \n",
      "3          4  8.904145  \n",
      "4          1  0.000000  \n",
      "\n",
      "--- Artificial Line Data ---\n",
      "   line_id  electrical_distance_to_substation        R1        X1\n",
      "0        0                           0.929698  0.360919  0.463249\n",
      "1        1                           0.808120  0.217322  0.610642\n",
      "2        2                           0.633404  1.242241  1.113390\n",
      "3        3                           0.871461  0.521802  0.321428\n",
      "4        4                           0.803672  0.055825  0.226756\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Create Artificial BUS Data ---\n",
    "N_BUSES = 10\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create normalized hop distance (0.0 to 1.0)\n",
    "hop_dist = np.random.rand(N_BUSES)\n",
    "\n",
    "# Create phases\n",
    "phases = np.random.choice(\n",
    "    ['A', 'B', 'C', 'AB', 'BC', 'BC', 'ABC'], \n",
    "    N_BUSES, \n",
    "    p=[0.15, 0.15, 0.15, 0.1, 0.1, 0.1, 0.25] # Biased towards 3-phase\n",
    ")\n",
    "\n",
    "# Create power, then zero-out non-existing phases\n",
    "P_A = np.random.lognormal(4, 1, N_BUSES)\n",
    "P_B = np.random.lognormal(4, 1, N_BUSES)\n",
    "P_C = np.random.lognormal(4, 1, N_BUSES)\n",
    "\n",
    "mask_no_A = np.char.find(phases, 'A') == -1\n",
    "mask_no_B = np.char.find(phases, 'B') == -1\n",
    "mask_no_C = np.char.find(phases, 'C') == -1\n",
    "\n",
    "# Apply the masks\n",
    "P_A[mask_no_A] = 0\n",
    "P_B[mask_no_B] = 0\n",
    "P_C[mask_no_C] = 0\n",
    "\n",
    "# Create reliability data\n",
    "# Frequency (count data, use Poisson)\n",
    "fic = np.random.poisson(lam=1.0 + hop_dist * 3, size=N_BUSES) # Freq increases with distance\n",
    "# Duration (use Weibull, with ~30% zeros for the \"hurdle\")\n",
    "dur = np.array([0 if np.random.rand() < 0.3 else np.random.weibull(1.5) * (2 + hop_dist*5) \n",
    "                for hop_dist in hop_dist])\n",
    "\n",
    "# Assemble the Bus DataFrame\n",
    "raw_bus_data = pd.DataFrame({\n",
    "    'bus_id': range(N_BUSES),\n",
    "    'hop_distance_normalized': hop_dist,\n",
    "    'phases': phases,\n",
    "    'P_A': P_A,\n",
    "    'P_B': P_B,\n",
    "    'P_C': P_C,\n",
    "    'FIC_total': fic,\n",
    "    'duration': dur\n",
    "})\n",
    "\n",
    "print(\"--- Artificial Bus Data ---\")\n",
    "print(raw_bus_data.head())\n",
    "\n",
    "\n",
    "# --- 2. Create Artificial LINE Data ---\n",
    "N_LINES = 20\n",
    "elec_dist = np.random.rand(N_LINES)\n",
    "\n",
    "# Create R1 and X1 (Gamma is good for positive, skewed data)\n",
    "R1 = np.random.gamma(2, 0.1 + elec_dist * 0.2, N_LINES)\n",
    "X1 = np.random.gamma(3, 0.2 + elec_dist * 0.1, N_LINES)\n",
    "\n",
    "# Assemble the Line DataFrame\n",
    "raw_line_data = pd.DataFrame({\n",
    "    'line_id': range(N_LINES),\n",
    "    'electrical_distance_to_substation': elec_dist,\n",
    "    'R1': R1,\n",
    "    'X1': X1\n",
    "})\n",
    "\n",
    "print(\"\\n--- Artificial Line Data ---\")\n",
    "print(raw_line_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194a8279",
   "metadata": {},
   "source": [
    "## Checking the synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be0b4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_id</th>\n",
       "      <th>electrical_distance_to_substation</th>\n",
       "      <th>R1</th>\n",
       "      <th>X1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.929698</td>\n",
       "      <td>0.360919</td>\n",
       "      <td>0.463249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.808120</td>\n",
       "      <td>0.217322</td>\n",
       "      <td>0.610642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.633404</td>\n",
       "      <td>1.242241</td>\n",
       "      <td>1.113390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.871461</td>\n",
       "      <td>0.521802</td>\n",
       "      <td>0.321428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.803672</td>\n",
       "      <td>0.055825</td>\n",
       "      <td>0.226756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   line_id  electrical_distance_to_substation        R1        X1\n",
       "0        0                           0.929698  0.360919  0.463249\n",
       "1        1                           0.808120  0.217322  0.610642\n",
       "2        2                           0.633404  1.242241  1.113390\n",
       "3        3                           0.871461  0.521802  0.321428\n",
       "4        4                           0.803672  0.055825  0.226756"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_line_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8ace9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bus_id</th>\n",
       "      <th>hop_distance_normalized</th>\n",
       "      <th>phases</th>\n",
       "      <th>P_A</th>\n",
       "      <th>P_B</th>\n",
       "      <th>P_C</th>\n",
       "      <th>FIC_total</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.374540</td>\n",
       "      <td>A</td>\n",
       "      <td>19.829463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>ABC</td>\n",
       "      <td>74.757335</td>\n",
       "      <td>79.495309</td>\n",
       "      <td>7.693147</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>ABC</td>\n",
       "      <td>22.020546</td>\n",
       "      <td>29.944968</td>\n",
       "      <td>14.466186</td>\n",
       "      <td>3</td>\n",
       "      <td>2.955830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>B</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.784669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>8.904145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>B</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.913007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bus_id  hop_distance_normalized phases        P_A        P_B        P_C  \\\n",
       "0       0                 0.374540      A  19.829463   0.000000   0.000000   \n",
       "1       1                 0.950714    ABC  74.757335  79.495309   7.693147   \n",
       "2       2                 0.731994    ABC  22.020546  29.944968  14.466186   \n",
       "3       3                 0.598658      B   0.000000  40.784669   0.000000   \n",
       "4       4                 0.156019      B   0.000000  29.913007   0.000000   \n",
       "\n",
       "   FIC_total  duration  \n",
       "0          2  0.000000  \n",
       "1          3  0.000000  \n",
       "2          3  2.955830  \n",
       "3          4  8.904145  \n",
       "4          1  0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_bus_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ca6b92",
   "metadata": {},
   "source": [
    "## Section 1: Learning the Impedance Model (R1 & X1)\n",
    "\n",
    "This model learns the Gamma Mixture distribution for `R1` and `X1` based on the `electrical_distance_to_substation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c26c656f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_zones_impd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62f48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Learning new Impedance Model ---\n",
      "Preprocessing impedance data...\n",
      "Preprocessing complete. Found 20 valid lines across 9 zones.\n",
      "Fetching default R-model trace...\n",
      "Fetching default X-model trace...\n",
      "Loading R1 trace from C:\\Users\\hoc\\AppData\\Local\\bayesgrid\\bayesgrid\\Cache\\trace_r.nc...\n",
      "R1 model loaded. Trained with 10353 lines and 10 zones.\n",
      "Loading X1 trace from C:\\Users\\hoc\\AppData\\Local\\bayesgrid\\bayesgrid\\Cache\\trace_x.nc...\n",
      "X1 model loaded. Trained with 10353 lines and 10 zones.\n",
      "\n",
      "Learning R1 model...\n",
      "Building r1_likelihood model for learning with 20 lines...\n",
      "Starting sampling with args: {'draws': 500, 'tune': 500, 'cores': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [mean_1, mean_2_offset, mean_3_offset, cv, w_by_zone]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 500 tune and 500 draw iterations (1_000 + 1_000 draws total) took 246 seconds.\n",
      "There were 6 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning complete.\n",
      "\n",
      "Learning X1 model...\n",
      "Building x1_likelihood model for learning with 20 lines...\n",
      "Starting sampling with args: {'draws': 500, 'tune': 500, 'cores': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [mean_1, mean_2_offset, mean_3_offset, cv, w_by_zone]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 500 tune and 500 draw iterations (1_000 + 1_000 draws total) took 283 seconds.\n",
      "There were 20 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning complete.\n",
      "Trace saved to my_new_traces/my_r_trace.pickle\n",
      "Trace saved to my_new_traces/my_x_trace.pickle\n",
      "\n",
      "Impedance models learned and saved!\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Learning new Impedance Model ---\")\n",
    "\n",
    "# 1. Preprocess the data\n",
    "# We'll use 10 discrete zones for impedance\n",
    "(elec_zones, r1_vals, x1_vals, n_zones_impd) = preprocess_impedance_data(\n",
    "    raw_line_data, \n",
    "    n_discrete=9\n",
    ")\n",
    "\n",
    "# 2. Initialize an empty model\n",
    "# We pass trace_path=None to signal that we are in \"learn mode\"\n",
    "# and don't want to download the default traces.\n",
    "bim_new = BayesianImpedanceModel(trace_r_path=None, trace_x_path=None)\n",
    "\n",
    "# 3. Learn R1\n",
    "# We use small draws/tune for a fast tutorial.\n",
    "# For a real model, use 1000-2000.\n",
    "print(\"\\nLearning R1 model...\")\n",
    "trace_r = bim_new.learn_r(\n",
    "    elec_dist_idx=elec_zones,\n",
    "    r1_data=r1_vals,\n",
    "    n_zones=n_zones_impd,\n",
    "    draws=500, tune=500, cores=1\n",
    ")\n",
    "\n",
    "# 4. Learn X1\n",
    "print(\"\\nLearning X1 model...\")\n",
    "trace_x = bim_new.learn_x(\n",
    "    elec_dist_idx=elec_zones,\n",
    "    x1_data=x1_vals,\n",
    "    n_zones=n_zones_impd,\n",
    "    draws=500, tune=500, cores=1\n",
    ")\n",
    "\n",
    "\n",
    "# 5. Save the new traces\n",
    "os.makedirs(\"my_new_traces\", exist_ok=True)\n",
    "bim_new.save_trace(trace_r, 'my_new_traces/my_r_trace.nc')\n",
    "bim_new.save_trace(trace_x, 'my_new_traces/my_x_trace.nc')\n",
    "\n",
    "print(\"\\nImpedance models learned and saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbcdebc",
   "metadata": {},
   "source": [
    "You can now use the new learned trace file to create a synthetic grid. \n",
    "\n",
    "For example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c0dbe",
   "metadata": {},
   "source": [
    "## Section 2: Learning the Failure Frequency Model (CAIFI/FIC)\n",
    "\n",
    "This model learns the Negative Binomial distribution for `FIC_total` (failure counts) based on the `hop_distance_normalized`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd2e3eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Learning new Failure Frequency Model ---\n",
      "Preprocessing frequency data...\n",
      "Preprocessing complete. Found 10 buses across 8 zones.\n",
      "No trace_path provided. Fetching default pre-trained model...\n",
      "Loading trace from C:\\Users\\hoc\\AppData\\Local\\bayesgrid\\bayesgrid\\Cache\\trace_fic.nc...\n",
      "Successfully loaded pre-trained model.\n",
      "Model was trained with 9328 buses and 30 zones.\n",
      "\n",
      "Learning Frequency (FIC) model...\n",
      "Building model for learning with 10 buses and 8 zones...\n",
      "Starting sampling with args: {'draws': 500, 'tune': 500, 'cores': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [mu_by_zone, alpha_dispersion]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 500 tune and 500 draw iterations (1_000 + 1_000 draws total) took 55 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning complete. Trace is stored in self.trace.\n",
      "Trace saved to my_new_traces/my_freq_trace.nc\n",
      "\n",
      "Frequency model learned and saved!\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Learning new Failure Frequency Model ---\")\n",
    "\n",
    "# 1. Preprocess the data\n",
    "# We'll use 30 discrete zones for reliability\n",
    "(hop_zones_freq, freq_data, n_zones_freq) = preprocess_frequency_data(\n",
    "    raw_bus_data, \n",
    "    n_discrete=30, \n",
    "    frequency_col='FIC_total'\n",
    ")\n",
    "\n",
    "# 2. Initialize an empty model\n",
    "bfm_new = BayesianFrequencyModel(trace_path=None)\n",
    "\n",
    "# 3. Learn the model\n",
    "print(\"\\nLearning Frequency (FIC) model...\")\n",
    "trace_freq = bfm_new.learn(\n",
    "    hop_zone_idx=hop_zones_freq,\n",
    "    frequency_data=freq_data,\n",
    "    n_zones=n_zones_freq,\n",
    "    draws=500, tune=500, cores=1\n",
    ")\n",
    "\n",
    "# 4. Save the new trace\n",
    "bfm_new.save_trace('my_new_traces/my_freq_trace.nc')\n",
    "\n",
    "print(\"\\nFrequency model learned and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c73e1ed",
   "metadata": {},
   "source": [
    "## Section 3: Learning the Failure Duration Model (CAIDI/DIC)\n",
    "\n",
    "This model learns the Hurdle-Weibull distribution for `duration` (failure duration) based on the `hop_distance_normalized`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7c141d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Learning new Failure Duration Model ---\n",
      "Preprocessing duration data...\n",
      "Preprocessing complete. Found 10 total buses.\n",
      "Found 3 buses with positive duration.\n",
      "No trace_path provided. Fetching default pre-trained model...\n",
      "Loading trace from C:\\Users\\hoc\\AppData\\Local\\bayesgrid\\bayesgrid\\Cache\\trace_dic.nc...\n",
      "Successfully loaded pre-trained model.\n",
      "Model was trained with 13547 total buses\n",
      "(8299 positive) and 30 zones.\n",
      "\n",
      "Learning Duration (DIC) model...\n",
      "Building model for learning with 10 total buses\n",
      "(3 positive) and 8 zones...\n",
      "Starting sampling with args: {'draws': 500, 'tune': 500, 'cores': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [p_positive_by_zone, alpha_weibull_by_zone, beta_weibull_by_zone]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 500 tune and 500 draw iterations (1_000 + 1_000 draws total) took 75 seconds.\n",
      "There were 9 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning complete. Trace is stored in self.trace.\n",
      "Trace saved to my_new_traces/my_dur_trace.nc\n",
      "\n",
      "Duration model learned and saved!\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Learning new Failure Duration Model ---\")\n",
    "\n",
    "# 1. Preprocess the data\n",
    "# This function handes the \"hurdle\" logic automatically\n",
    "(hop_all, is_pos, hop_pos, pos_durs, n_zones_dur) = preprocess_duration_data(\n",
    "    raw_bus_data, \n",
    "    n_discrete=30, \n",
    "    duration_col='duration'\n",
    ")\n",
    "\n",
    "# 2. Initialize an empty model\n",
    "bdm_new = BayesianDurationModel(trace_path=None)\n",
    "\n",
    "# 3. Learn the model\n",
    "print(\"\\nLearning Duration (DIC) model...\")\n",
    "trace_dur = bdm_new.learn(\n",
    "    hop_zone_idx_all=hop_all,\n",
    "    is_positive_all=is_pos,\n",
    "    hop_zone_idx_positive=hop_pos,\n",
    "    positive_durations=pos_durs,\n",
    "    n_zones=n_zones_dur,\n",
    "    draws=500, tune=500, cores=1\n",
    ")\n",
    "\n",
    "# 4. Save the new trace\n",
    "bdm_new.save_trace('my_new_traces/my_dur_trace.nc')\n",
    "\n",
    "print(\"\\nDuration model learned and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd1b6b",
   "metadata": {},
   "source": [
    "## Section 4: Learning the Power & Phase Model\n",
    "\n",
    "This model learns the complex, graph-aware relationship between `phases`, `P_A`, `P_B`, `P_C`, and `hop_distance_normalized`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d106967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_power_and_phase_data(df, n_discrete=10, \n",
    "                    hop_col='hop_distance_normalized', \n",
    "                    phase_col='phases', \n",
    "                    power_cols=['P_A', 'P_B', 'P_C']):\n",
    "    \"\"\"\n",
    "    Preprocesses a raw DataFrame for the BayesianPowerModel.\n",
    "    ... (code from previous step, unchanged) ...\n",
    "    \"\"\"\n",
    "    print(\"Preprocessing data...\")\n",
    "    if hop_col not in df.columns:\n",
    "        raise ValueError(f\"Missing required column: {hop_col}\")\n",
    "    if phase_col not in df.columns:\n",
    "        raise ValueError(f\"Missing required column: {phase_col}\")\n",
    "\n",
    "    df_proc = df.copy()\n",
    "\n",
    "    # --- 1. Discretize Hop Distance ---\n",
    "    df_proc['hop_distance_discrete'] = pd.cut(\n",
    "        df_proc[hop_col], \n",
    "        bins=n_discrete, \n",
    "        labels=False, # Use integer labels 0 to n_discrete-1\n",
    "        include_lowest=True,\n",
    "        duplicates='drop'\n",
    "    )\n",
    "    \n",
    "    if df_proc['hop_distance_discrete'].isnull().any():\n",
    "        warnings.warn(\"NaNs found in 'hop_distance_discrete' after binning. Filling with zone 0.\")\n",
    "        df_proc['hop_distance_discrete'] = df_proc['hop_distance_discrete'].fillna(0)\n",
    "\n",
    "    df_proc['hop_zone_idx'] = pd.Categorical(df_proc['hop_distance_discrete']).codes\n",
    "    hop_zone_idx = df_proc['hop_zone_idx'].values.astype(int)\n",
    "    n_zones = len(np.unique(hop_zone_idx))\n",
    "\n",
    "    # --- 2. Encode Phases ---\n",
    "    phase_map = {'A': 0, 'B': 1, 'C': 2, 'AB': 3, 'AC': 4, 'BC': 5, 'ABC': 6}\n",
    "    \n",
    "\n",
    "    phase_category_idx = df_proc[phase_col].map(phase_map).fillna(-1).astype(int)\n",
    "    \n",
    "    # --- 3. Filter out invalid data ---\n",
    "    valid_mask = (phase_category_idx != -1)\n",
    "    if not valid_mask.all():\n",
    "        n_dropped = (~valid_mask).sum()\n",
    "        warnings.warn(f\"Dropping {n_dropped} buses with unknown phase categories.\")\n",
    "        df_proc = df_proc[valid_mask]\n",
    "        hop_zone_idx = hop_zone_idx[valid_mask]\n",
    "        phase_category_idx = phase_category_idx[valid_mask]\n",
    "\n",
    "    # --- 4. Get Power Array ---\n",
    "    if all(col in df_proc.columns for col in power_cols):\n",
    "         power_array = df_proc[power_cols].values\n",
    "         if np.isnan(power_array).any():\n",
    "             n_nans = np.isnan(power_array).sum()\n",
    "             warnings.warn(f\"Found {n_nans} NaNs in power data. Replacing with 0.0.\")\n",
    "             power_array = np.nan_to_num(power_array, nan=0.0)\n",
    "    else:\n",
    "        warnings.warn(f\"Power columns {power_cols} not found. Returning None for power array.\")\n",
    "        power_array = None\n",
    "\n",
    "    print(f\"Preprocessing complete. {len(hop_zone_idx)} valid buses found across {n_zones} zones.\")\n",
    "    return hop_zone_idx, phase_category_idx, power_array, n_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5a1996c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Learning new Power and Phase Model ---\n",
      "Preprocessing data...\n",
      "Preprocessing complete. 10 valid buses found across 6 zones.\n",
      "No trace_path provided. Fetching default pre-trained model...\n",
      "Loading trace from C:\\Users\\hoc\\AppData\\Local\\bayesgrid\\bayesgrid\\Cache\\trace_power_and_phase.nc...\n",
      "Successfully loaded pre-trained model.\n",
      "Model was trained with 3599 buses and 10 zones.\n",
      "\n",
      "Learning Power and Phase model...\n",
      "Building model for learning with 10 buses and 10 zones...\n",
      "Starting sampling with args: {'draws': 500, 'tune': 500, 'cores': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [a_by_zone, probs, alpha_mono, beta_mono, P_potential_mono, alpha_bi, beta_bi, P_potential_bi_total, split_factor_bi, alpha_tri, beta_tri, P_potential_tri_total, split_factor_tri, sigma_p]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\hoc\\anaconda3\\envs\\bhmenv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow \n",
       "encountered in reduce\n",
       "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\hoc\\anaconda3\\envs\\bhmenv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow \n",
       "encountered in reduce\n",
       "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\hoc\\anaconda3\\envs\\bhmenv\\Lib\\site-packages\\pytensor\\tensor\\elemwise.py:710: RuntimeWarning: overflow \n",
       "encountered in impl (vectorized)\n",
       "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\hoc\\anaconda3\\envs\\bhmenv\\Lib\\site-packages\\pytensor\\tensor\\elemwise.py:710: RuntimeWarning: overflow \n",
       "encountered in impl (vectorized)\n",
       "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\hoc\\anaconda3\\envs\\bhmenv\\Lib\\site-packages\\pytensor\\tensor\\elemwise.py:710: RuntimeWarning: overflow \n",
       "encountered in exp\n",
       "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\hoc\\anaconda3\\envs\\bhmenv\\Lib\\site-packages\\pytensor\\tensor\\elemwise.py:710: RuntimeWarning: overflow \n",
       "encountered in exp\n",
       "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 500 tune and 500 draw iterations (1_000 + 1_000 draws total) took 1897 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning complete. Trace is stored in self.trace.\n",
      "Trace saved to my_new_traces/my_power_trace.nc\n",
      "\n",
      "Power & Phase model learned and saved!\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Learning new Power and Phase Model ---\")\n",
    "\n",
    "# 1. Preprocess the data\n",
    "# This function automatically handles phase encoding and power values\n",
    "(hop_zones_power, phases_idx, power_vals, n_zones_power) = preprocess_power_and_phase_data(\n",
    "    raw_bus_data, \n",
    "    n_discrete=10\n",
    ")\n",
    "\n",
    "# 2. Initialize an empty model\n",
    "bhm_new = BayesianPowerModel(trace_path=None)\n",
    "\n",
    "# 3. Learn the model\n",
    "# This model is the most complex and may take longer\n",
    "print(\"\\nLearning Power and Phase model...\")\n",
    "trace_power = bhm_new.learn(\n",
    "    hop_zone_idx=hop_zones_power,\n",
    "    observed_phases=phases_idx,\n",
    "    observed_power_p=power_vals,\n",
    "    n_zones=10,\n",
    "    draws=500, tune=500, cores=1\n",
    ")\n",
    "\n",
    "# 4. Save the new trace\n",
    "bhm_new.save_trace('my_new_traces/my_power_trace.nc')\n",
    "\n",
    "print(\"\\nPower & Phase model learned and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d628155",
   "metadata": {},
   "source": [
    "\n",
    "## Tutorial Complete!\n",
    "\n",
    "You have successfully trained a full set of custom Bayesian models on your own (artificial) dataset.\n",
    "\n",
    "You now have a folder `my_new_traces/` containing:\n",
    "\n",
    "  * `my_r_trace.nc`\n",
    "  * `my_x_trace.nc`\n",
    "  * `my_freq_trace.nc`\n",
    "  * `my_dur_trace.nc`\n",
    "  * `my_power_trace.nc`\n",
    "\n",
    "### How to use your new models:\n",
    "\n",
    "In your other notebooks (like the `pandapower` or `OSM` tutorials), simply point the model's `__init__` constructor to your new file paths. The generation code will use your custom-trained models instead of the downloaded defaults.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "# Instead of this:\n",
    "# bhm = BayesianPowerModel()\n",
    "\n",
    "# Do this:\n",
    "bhm = BayesianPowerModel(trace_path='my_new_traces/my_power_trace.nc')\n",
    "\n",
    "# ...and the same for the other models...\n",
    "bfm = BayesianFrequencyModel(trace_path='my_new_traces/my_freq_trace.nc')\n",
    "bdm = BayesianDurationModel(trace_path='my_new_traces/my_dur_trace.nc')\n",
    "bim = BayesianImpedanceModel(\n",
    "    trace_r_path='my_new_traces/my_r_trace.nc',\n",
    "    trace_x_path='my_new_traces/my_x_trace.nc'\n",
    ")\n",
    "\n",
    "# Now, all generation code will use YOUR trained models!\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bhmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
